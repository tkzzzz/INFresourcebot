print("--- Python script bot.py is starting NOW ---")
import discord
from discord.ext import commands, tasks
import feedparser
import os
import logging
import asyncio # Though not directly used for new tasks, good to have for context
from datetime import datetime, timezone # For timestamp conversion
import re # For cleaning up HTML and extracting image URLs

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Configuration ---
RSS_FEED_URL = "https://feeds.feedburner.com/GalaxyHarvesterResourceActivity"
TARGET_SERVER_NAME = "Sentinels Republic 2"
CHECK_INTERVAL_SECONDS = 300
MAX_SEEN_ENTRIES = 200

# --- Environment Variables ---
DISCORD_BOT_TOKEN = os.getenv("DISCORD_BOT_TOKEN")
try:
    DISCORD_CHANNEL_ID = int(os.getenv("DISCORD_CHANNEL_ID", 0))
except ValueError:
    logging.error("DISCORD_CHANNEL_ID is not a valid integer. Please check your environment variables.")
    DISCORD_CHANNEL_ID = 0

# --- Bot Setup ---
intents = discord.Intents.default()
bot = commands.Bot(command_prefix="!ghrep ", intents=intents)
seen_entry_guids = []

# --- Helper Function ---
def parse_summary_to_dict(summary_html_content):
    """
    Parses the cleaned summary text (lines of "Key: Value") into a dictionary.
    Also extracts image URL if present.
    """
    data = {}
    
    # First, try to extract image URL
    img_url = None
    img_match = re.search(r"<img\s+.*?src=['\"]([^'\"]+)['\"]", summary_html_content, re.IGNORECASE)
    if img_match:
        img_url = img_match.group(1)
        if img_url.startswith('/'): # Handle relative URLs from Galaxy Harvester
            img_url = "https://galaxyharvester.net" + img_url
    data['image_url'] = img_url

    # Prepare text for key-value parsing: replace <br> with newlines, then strip other tags
    text_for_parsing = summary_html_content.replace('<br />', '\n').replace('<br/>', '\n').replace('<br>', '\n')
    text_for_parsing = re.sub(r'<[^>]+>', '', text_for_parsing) # Strip remaining HTML tags

    for line in text_for_parsing.split('\n'):
        line = line.strip()
        if ":" in line:
            parts = line.split(":", 1)
            key = parts[0].strip()
            value = parts[1].strip()
            data[key] = value
    return data

@bot.event
async def on_ready():
    """Called when the bot successfully connects to Discord."""
    logging.info(f'{bot.user.name} has connected to Discord!')
    if DISCORD_CHANNEL_ID == 0:
        logging.error("DISCORD_CHANNEL_ID is not set or invalid. Bot will not be able to send messages.")
    else:
        logging.info(f'Monitoring RSS feed for "{TARGET_SERVER_NAME}" updates.')
        logging.info(f'Messages will be posted to channel ID: {DISCORD_CHANNEL_ID}')
        channel = bot.get_channel(DISCORD_CHANNEL_ID)
        if not channel:
            logging.warning(f"Could not find channel with ID {DISCORD_CHANNEL_ID}. Messages will not be sent.")
        fetch_rss_feed_task.start()

@tasks.loop(seconds=CHECK_INTERVAL_SECONDS)
async def fetch_rss_feed_task():
    """Periodically fetches and processes the RSS feed."""
    global seen_entry_guids
    if DISCORD_CHANNEL_ID == 0:
        logging.warning("Skipping RSS fetch: DISCORD_CHANNEL_ID not set.")
        return

    logging.info(f"Fetching RSS feed: {RSS_FEED_URL}")
    try:
        feed = await bot.loop.run_in_executor(None, feedparser.parse, RSS_FEED_URL)
        
        if feed.bozo:
            logging.error(f"Error parsing RSS feed. Details: {feed.bozo_exception}")
            return

        channel = bot.get_channel(DISCORD_CHANNEL_ID)
        if not channel:
            logging.error(f"Channel ID {DISCORD_CHANNEL_ID} not found. Cannot send messages.")
            return

        new_entries_to_post = []
        for entry in feed.entries:
            entry_guid = entry.get("guid", entry.link)
            if entry_guid not in seen_entry_guids:
                if TARGET_SERVER_NAME.lower() in entry.title.lower():
                    new_entries_to_post.append(entry)
        
        current_fetch_guids = [e.get("guid", e.link) for e in feed.entries]
        for guid_from_fetch in current_fetch_guids:
            if guid_from_fetch not in seen_entry_guids:
                seen_entry_guids.append(guid_from_fetch)
        
        if new_entries_to_post:
            logging.info(f"Found {len(new_entries_to_post)} new relevant entries for '{TARGET_SERVER_NAME}'.")
            
            def get_sort_key(e):
                dt_struct = e.get("published_parsed") or e.get("updated_parsed")
                if dt_struct:
                    try:
                        return datetime(*dt_struct[:6], tzinfo=timezone.utc)
                    except ValueError:
                        return datetime.min.replace(tzinfo=timezone.utc)
                return datetime.min.replace(tzinfo=timezone.utc)

            for entry_to_post in sorted(new_entries_to_post, key=get_sort_key):
                logging.info(f"Posting entry: {entry_to_post.title}")

                summary_html = entry_to_post.get('summary', entry_to_post.get('description', ''))
                parsed_data = parse_summary_to_dict(summary_html)

                resource_name_parsed = parsed_data.get("Resource Name")
                resource_type_parsed = parsed_data.get("Resource Type")

                embed_title = ""
                if resource_name_parsed and resource_type_parsed:
                    embed_title = f"{resource_name_parsed} {resource_type_parsed} at Galaxy Harvester"
                else:
                    # Fallback to cleaning the original entry title
                    cleaned_entry_title = entry_to_post.title.replace(TARGET_SERVER_NAME, "", 1).lstrip(" ()-").strip()
                    if "(SWGemu)" in cleaned_entry_title: # Further clean common server tags
                        cleaned_entry_title = cleaned_entry_title.replace("(SWGemu)", "", 1).lstrip(" ()-").strip()
                    embed_title = f"New Resource: {cleaned_entry_title if cleaned_entry_title else entry_to_post.title}"

                embed = discord.Embed(
                    title=embed_title,
                    url=entry_to_post.link,
                    color=discord.Color.dark_teal() # Example color
                )
                embed.set_author(
                    name=f"{TARGET_SERVER_NAME} - Galaxy Harvester",
                    icon_url="https://galaxyharvester.net/images/galaxyharvester/logoRefresh.png"
                )

                if parsed_data.get('image_url'):
                    embed.set_thumbnail(url=parsed_data['image_url'])

                description_lines = []
                description_lines.append(f"**Type:** {resource_type_parsed or 'N/A'}")
                # Resource name is already prominent in the title, could be omitted here if too redundant
                # description_lines.append(f"**Name:** {resource_name_parsed or 'N/A'}") 
                description_lines.append(f"**Planet(s):** {parsed_data.get('Planet(s)', 'N/A')}")
                description_lines.append("") # Blank line for spacing

                # Key stats section
                description_lines.append(f"**Key Stats:**")
                oq_text = parsed_data.get("Overall Quality", "N/A")
                dr_text = parsed_data.get("Decay Resistance", "N/A")
                fl_text = parsed_data.get("Flavor", "N/A")
                pe_text = parsed_data.get("Potential Energy", "N/A")
                description_lines.append(f"  OQ: {oq_text}")
                description_lines.append(f"  DR: {dr_text}")
                description_lines.append(f"  FL: {fl_text}")
                description_lines.append(f"  PE: {pe_text}")
                description_lines.append("") # Blank line

                description_lines.append("**All Stats:**")
                stat_map_abbr_to_full = {
                    "ER": "Entangle Resistance", "CR": "Cold Resistance", "CD": "Conductivity",
                    "DR": "Decay Resistance", "FL": "Flavor", "HR": "Heat Resistance",
                    "MA": "Malleability", "PE": "Potential Energy", "OQ": "Overall Quality",
                    "SR": "Shock Resistance", "UT": "Unit Toughness"
                }
                for abbr, full_name in stat_map_abbr_to_full.items():
                    value = parsed_data.get(full_name, "N/A")
                    # Using monospace for alignment: `abbr` left-aligned in 3 chars
                    description_lines.append(f"`{abbr:<3}`: {value}") 

                embed.description = "\n".join(description_lines)[:4096] # Discord embed description limit

                published_time_struct = entry_to_post.get("published_parsed")
                if published_time_struct:
                    try:
                        embed.timestamp = datetime(*published_time_struct[:6], tzinfo=timezone.utc)
                    except ValueError:
                         logging.warning(f"Could not parse timestamp for embed: {entry_to_post.get('published')}")
                         embed.set_footer(text=f"Published: {entry_to_post.get('published', 'N/A')}")
                else:
                    embed.set_footer(text=f"Link: {entry_to_post.link}")
                
                try:
                    await channel.send(embed=embed)
                except discord.Forbidden:
                    logging.error(f"Bot lacks permission to send embeds/messages in channel {DISCORD_CHANNEL_ID}.")
                    break 
                except discord.HTTPException as e:
                    logging.error(f"Failed to send message due to HTTPException: {e}")
        else:
            logging.info("No new relevant entries found in this check.")

        if len(seen_entry_guids) > MAX_SEEN_ENTRIES:
            logging.info(f"Trimming seen_entry_guids. Old size: {len(seen_entry_guids)}")
            seen_entry_guids = seen_entry_guids[-MAX_SEEN_ENTRIES:]
            logging.info(f"New size after trimming: {len(seen_entry_guids)}")

    except aiohttp.ClientError as e:
        logging.error(f"Network error during RSS fetch (aiohttp.ClientError): {e}")
    except Exception as e:
        logging.exception("An unexpected error occurred during RSS fetch or processing:")

@fetch_rss_feed_task.before_loop
async def before_fetch_rss_feed_task():
    global seen_entry_guids
    logging.info("Waiting for bot to be ready before starting RSS fetch loop...")
    await bot.wait_until_ready()
    logging.info("Bot is ready. Initializing 'seen entries' list from current feed...")
    try:
        feed = await bot.loop.run_in_executor(None, feedparser.parse, RSS_FEED_URL)
        if feed.bozo:
            logging.warning(f"Error parsing RSS feed during pre-population: {feed.bozo_exception}")
            return
        
        initial_guids = [entry.get("guid", entry.link) for entry in feed.entries]
        temp_seen_guids = list(dict.fromkeys(initial_guids)) 
        
        if len(temp_seen_guids) > MAX_SEEN_ENTRIES:
            seen_entry_guids = temp_seen_guids[:MAX_SEEN_ENTRIES]
        else:
            seen_entry_guids = temp_seen_guids
            
        logging.info(f"Pre-populated {len(seen_entry_guids)} entries as 'seen'. Max capacity: {MAX_SEEN_ENTRIES}")

    except Exception as e:
        logging.exception("Error during initial RSS feed fetch for pre-population:")

# --- Main Execution ---
def main():
    if not DISCORD_BOT_TOKEN:
        logging.critical("FATAL ERROR: DISCORD_BOT_TOKEN environment variable not set.")
        return
    if DISCORD_CHANNEL_ID == 0:
        logging.critical("FATAL ERROR: DISCORD_CHANNEL_ID environment variable not set or invalid.")
        return
    
    logging.info("Attempting to start the bot...")
    try:
        bot.run(DISCORD_BOT_TOKEN)
    except discord.LoginFailure:
        logging.critical("Login failed: Invalid DISCORD_BOT_TOKEN.")
    except discord.PrivilegedIntentsRequired:
        logging.critical("Privileged intents are required but not enabled.")
    except Exception as e:
        logging.critical(f"An critical error occurred while trying to run the bot: {e}", exc_info=True)

if __name__ == "__main__":
    main()
